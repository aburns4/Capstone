{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Andrea Burns\n",
    "#Data Reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read each data frame in from my excel sheets\n",
    "xls = pd.ExcelFile('DataDownload.xls')\n",
    "df1 = pd.read_excel(xls, 'ACCESS')\n",
    "df2 = pd.read_excel(xls, 'STORES')\n",
    "df3 = pd.read_excel(xls, 'RESTAURANTS')\n",
    "df4 = pd.read_excel(xls, 'ASSISTANCE')\n",
    "df5 = pd.read_excel(xls, 'INSECURITY')\n",
    "df6 = pd.read_excel(xls, 'PRICES_TAXES')\n",
    "df7 = pd.read_excel(xls, 'LOCAL')\n",
    "df8 = pd.read_excel(xls, 'HEALTH')\n",
    "df9 = pd.read_excel(xls, 'SOCIOECONOMIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these will be my output space; I'll try to predict these features\n",
    "diabetes08 = df8['PCT_DIABETES_ADULTS08'].as_matrix()\n",
    "diabetes13 = df8['PCT_DIABETES_ADULTS13'].as_matrix()\n",
    "obesity08 = df8['PCT_OBESE_ADULTS08'].as_matrix()\n",
    "obesity13 = df8['PCT_OBESE_ADULTS13'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove my Y from the feature space to train on\n",
    "df8 = df8.drop('PCT_DIABETES_ADULTS08', 1)\n",
    "df8 = df8.drop('PCT_DIABETES_ADULTS13', 1)\n",
    "df8 = df8.drop('PCT_OBESE_ADULTS08', 1)\n",
    "df8 = df8.drop('PCT_OBESE_ADULTS13', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alldata = [df1,df2,df3,df4,df5,df6,df7,df8,df9] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting all instances\n",
    "X = []\n",
    "i = 0\n",
    "for i in range(0,3143):\n",
    "    current_row = []\n",
    "    for frame in alldata:\n",
    "        mat = frame.as_matrix()\n",
    "        current_row.append(mat[i][3:])\n",
    "    X.append(list(itertools.chain(*current_row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some features are missing data for specific instances, so I want to find them and deal with them\n",
    "missing = np.argwhere(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 4, 6, 7, 9, 11, 12, 14, 15, 16, 18, 19, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 46, 49, 52, 55, 58, 61, 64, 67, 69, 70, 73, 76, 79, 82, 85, 88, 93, 94, 95, 99, 100, 101, 115, 116, 117, 118, 125, 126, 127, 128, 129, 130, 146, 147, 148, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 254, 257, 266, 267, 269, 272}\n"
     ]
    }
   ],
   "source": [
    "feats = []\n",
    "for i in range(0,len(missing)):\n",
    "    feats.append(missing[i][1])\n",
    "print(set(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are two of the ~10 categorical features. Only these two have missing features\n",
    "#since they are 0 or 1 binary classes, it doesn't make sense to replace NaN values with the mean of the column\n",
    "#so instead I replace it will -1 as a \"missing\" class\n",
    "for i in range(0,len(missing)):\n",
    "    if missing[i][1] == 249:\n",
    "        X[missing[i][0]][249] = -1\n",
    "    elif missing[i][1] == 250:\n",
    "        X[missing[i][0]][250] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all other features are continuous so I can impute NaN values with the mean of the feature!\n",
    "from sklearn.preprocessing import Imputer\n",
    "# missing_values is the value of your placeholder, strategy is if you'd like mean, median or mode, and axis=0 means it calculates the imputation based on the other feature values for that sample\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "train_imp = imp.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
